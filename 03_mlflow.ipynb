{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bec3850",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "This notebook provides an introduction to mlflw tracking using a local folder and a sqlite database. The data can be found on [Kaggle](www.kaggle.com): https://www.kaggle.com/datasets/harlfoxem/housesalesprediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb07e41",
   "metadata": {},
   "source": [
    "nessecary packages for mlflow: ```pip install mlflow```\n",
    "\n",
    "necessary packages to use the web ui using sqlite ```pip install sqlalchemy```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c706b8",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6efb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699fb105",
   "metadata": {},
   "source": [
    "# Regression Model\n",
    "\n",
    "We will first train a regression model using Random Forest Regressor. We will do some prior preprocessing of the data, which can be found in the notebook 01_linear_regression_xgboost. We will apply the preprocessing explored there. For further details please refer to this notebook. \n",
    "\n",
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9607e239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755bc51",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Here we define a function that performs the preprocessing explored in notebook 01_linear_regression_xgboost. For the purpose of this notebook we will divide the dataset in a training and validation set and omit the third test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6d6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    \n",
    "    # used columns\n",
    "    columns = ['sqft_living','grade', 'sqft_above', 'sqft_living15',\n",
    "           'bathrooms','view','sqft_basement','lat','long','waterfront',\n",
    "           'yr_built','bedrooms']\n",
    "    # Delete entry with 33 bedrooms\n",
    "    df = df[df[\"bedrooms\"] != 33]\n",
    "    \n",
    "    # Convert grade, view, waterfront to type object\n",
    "    df[['grade','view','waterfront']] = df[['grade','view','waterfront']].astype('object')\n",
    "    \n",
    "    # Create training and validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df[columns], df['price'], test_size=0.2, shuffle=True, random_state=42)\n",
    "    print(f'train data shape: X - {X_train.shape}, y - {y_train.shape}')\n",
    "    print(f'validation data shape: X - {X_val.shape}, y - {y_val.shape}')\n",
    "    \n",
    "    # log transform the target varibale \n",
    "    y_train = np.log1p(y_train)\n",
    "    y_val = np.log1p(y_val)\n",
    "    \n",
    "    # define categorical and numerical varibales \n",
    "    categorical = ['grade', 'view', 'waterfront']\n",
    "    numerical = ['sqft_living', 'sqft_above', 'sqft_living15',\n",
    "           'bathrooms','sqft_basement','lat','long',\n",
    "           'yr_built','bedrooms']\n",
    "    \n",
    "    # one-hot encode categorical variables\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_cat = ohe.fit_transform(X_train[categorical]).toarray()\n",
    "    X_val_cat = ohe.transform(X_val[categorical]).toarray()\n",
    "    \n",
    "    # define numerical columns \n",
    "    X_train_num = np.array(X_train[numerical])\n",
    "    X_val_num = np.array(X_val[numerical])\n",
    "    \n",
    "    # concatenate numerical and categorical variables\n",
    "    X_train = np.concatenate([X_train_cat, X_train_num], axis=1)\n",
    "    X_val = np.concatenate([X_val_cat, X_val_num], axis=1)\n",
    "    print('Shapes after one-hot encoding')\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape {X_val.shape}')\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6807e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: X - (17289, 12), y - (17289,)\n",
      "validation data shape: X - (4323, 12), y - (4323,)\n",
      "Shapes after one-hot encoding\n",
      "X_train shape: (17289, 28), X_val shape (4323, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94519/2393366215.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['grade','view','waterfront']] = df[['grade','view','waterfront']].astype('object')\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = preprocessing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be01477",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "### Experiment Tracking using mlflow\n",
    "Define a function for fitting and evaluating a Random forest Regressor Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc9c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(X_train, y_train, X_val, y_val, n_estimators=100, max_depth=6):\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred_train = model.predict(X_train).reshape(-1,1)\n",
    "    y_pred = model.predict(X_val).reshape(-1,1)\n",
    "    \n",
    "    # calculate errors\n",
    "    rmse_train = mean_squared_error(y_pred_train, y_train, squared=False)\n",
    "    rmse_val = mean_squared_error(y_pred, y_val, squared=False)\n",
    "    print(f\"rmse training: {rmse_train:.3f}\\t rmse validation: {rmse_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99760591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse training: 0.219\t rmse validation: 0.229\n"
     ]
    }
   ],
   "source": [
    "train_rf(X_train, y_train,X_val, y_val, n_estimators=100, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017aae1",
   "metadata": {},
   "source": [
    "Now log several paramters and metrics using mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12918650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(X_train, y_train, X_val, y_val, n_estimators=100, max_depth=6):\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred_train = model.predict(X_train).reshape(-1,1)\n",
    "    y_pred = model.predict(X_val).reshape(-1,1)\n",
    "    \n",
    "    # calculate errors\n",
    "    rmse_train = mean_squared_error(y_pred_train, y_train, squared=False)\n",
    "    rmse_val = mean_squared_error(y_pred, y_val, squared=False)\n",
    "    print(f\"rmse training: {rmse_train:.3f}\\t rmse validation: {rmse_val:.3f}\")\n",
    "    \n",
    "    # Logging params and metrics to MLFlow\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_param('max_depth', max_depth)\n",
    "    mlflow.log_metric('rmse_val', rmse_val)\n",
    "    mlflow.log_metric('rmse_train', rmse_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63390bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse training: 0.219\t rmse validation: 0.228\n"
     ]
    }
   ],
   "source": [
    "train_rf(X_train, y_train, X_val, y_val, n_estimators=100, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb1c4a",
   "metadata": {},
   "source": [
    "### Store logs in a local  Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6233295",
   "metadata": {},
   "source": [
    "The easiest way to track our experiments is to save all the logged information in a local folder. We can do this by using ```with mlflow.start_run()``` and run our model in the ```with``` statement. A directory ```'./mlflow'```, where the runs and all associated loggings are saved is created. Every time we run code with the command ```with mlflow.start_run()``` a new run will be created under the same experiment name. By default the experiment is named ```0```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5359705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse training: 0.219\t rmse validation: 0.228\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    train_rf(X_train, y_train, X_val, y_val, n_estimators=100, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de491559",
   "metadata": {},
   "source": [
    "We perform a new run of the model changing the \"max_depth\" parameter. If we run it as above it will be stored under the current experiment folder as the previous, in this case with experiment_id=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e58de0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse training: 0.072\t rmse validation: 0.185\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    train_rf(X_train, y_train, X_val, y_val, n_estimators=100, max_depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6223ae",
   "metadata": {},
   "source": [
    "If we want to save our results under a different experiment, we can set a new experiment, using ```mlflow.set_experiment()```. If the experiment exists it will save the runs under this experiment, if it doesn't exist it will create a new one.\n",
    "\n",
    "Let us create a second model and log parameters and metrics as in the previous example, this time using XGBoost. We want to save the results under a new experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2184270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X_train, y_train,Xval, y_val, \n",
    "              n_estimators=100,\n",
    "              objective='reg:squarederror',\n",
    "              learning_rate=0.3,\n",
    "              min_child_weight=1,\n",
    "              lambda_=1,\n",
    "              gamma=0):\n",
    "    \n",
    "    # Initialize XGB with objective function\n",
    "    parameters = {\"objective\": objective,\n",
    "              \"n_estimators\": n_estimators,\n",
    "              \"eta\": learning_rate,\n",
    "              \"lambda\": lambda_,\n",
    "              \"gamma\": gamma,\n",
    "              \"max_depth\": None,\n",
    "              \"min_child_weight\": min_child_weight,\n",
    "              \"verbosity\": 0}\n",
    "\n",
    "    \n",
    "    model = xgb.XGBRegressor(**parameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred_train = model.predict(X_train).reshape(-1,1)\n",
    "    y_pred = model.predict(X_val).reshape(-1,1)\n",
    "    \n",
    "    # calculate errors\n",
    "    rmse_train = mean_squared_error(y_pred_train, y_train, squared=False)\n",
    "    rmse_val = mean_squared_error(y_pred, y_val, squared=False)\n",
    "    print(f\"rmse training: {rmse_train:.3f}\\t rmse validation: {rmse_val:.3f}\")\n",
    "    \n",
    "    # Logging params and metrics to MLFlow\n",
    "    mlflow.log_param('n_estimators', n_estimators)\n",
    "    mlflow.log_param('objective', objective)\n",
    "    mlflow.log_param('lambda', lambda_)\n",
    "    mlflow.log_param('gamma', gamma)\n",
    "    mlflow.log_param('eta', learning_rate)\n",
    "    mlflow.log_param('min_child_weight', min_child_weight)\n",
    "    mlflow.log_metric('rmse_val', rmse_val)\n",
    "    mlflow.log_metric('rmse_train', rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d970abaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/05/26 19:13:02 INFO mlflow.tracking.fluent: Experiment with name 'xgboost' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse training: 0.156\t rmse validation: 0.178\n"
     ]
    }
   ],
   "source": [
    "# defining a new experiment\n",
    "experiment_name = 'xgboost'\n",
    "exp_id = mlflow.set_experiment(experiment_name=experiment_name)\n",
    "with mlflow.start_run():\n",
    "    train_xgb(X_train, y_train, X_val, y_val, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dfab7b",
   "metadata": {},
   "source": [
    "We can run models under specific experiment names, by setting the experiment_id to an existing experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53c915d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse training: 4.606\t rmse validation: 4.612\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=1):\n",
    "    train_xgb(X_train, y_train, X_val, y_val, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430750e",
   "metadata": {},
   "source": [
    "Using ```tree mlruns``` we can see the structure of the folder, where our runs are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2d9b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mmlruns\u001b[00m\r\n",
      "â”œâ”€â”€ \u001b[01;34m0\u001b[00m\r\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;34m29ed490ed510441692142a030a392a37\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34martifacts\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ meta.yaml\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34mmetrics\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ rmse_train\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ rmse_val\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34mparams\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ max_depth\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ n_estimators\r\n",
      "â”‚Â Â  â”‚Â Â  â””â”€â”€ \u001b[01;34mtags\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.git.commit\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.name\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.type\r\n",
      "â”‚Â Â  â”‚Â Â      â””â”€â”€ mlflow.user\r\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;34m5cb2dbf0b0584f81bd2c45b5d1bdadee\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34martifacts\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ meta.yaml\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34mmetrics\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ rmse_train\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ rmse_val\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34mparams\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ max_depth\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ n_estimators\r\n",
      "â”‚Â Â  â”‚Â Â  â””â”€â”€ \u001b[01;34mtags\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.git.commit\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.name\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.type\r\n",
      "â”‚Â Â  â”‚Â Â      â””â”€â”€ mlflow.user\r\n",
      "â”‚Â Â  â”œâ”€â”€ \u001b[01;34mc95dfd97e79a471e8e79feda44362a10\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34martifacts\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ meta.yaml\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34mmetrics\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ rmse_train\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ rmse_val\r\n",
      "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ \u001b[01;34mparams\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ max_depth\r\n",
      "â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ n_estimators\r\n",
      "â”‚Â Â  â”‚Â Â  â””â”€â”€ \u001b[01;34mtags\u001b[00m\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.git.commit\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.name\r\n",
      "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.source.type\r\n",
      "â”‚Â Â  â”‚Â Â      â””â”€â”€ mlflow.user\r\n",
      "â”‚Â Â  â””â”€â”€ meta.yaml\r\n",
      "â””â”€â”€ \u001b[01;34m1\u001b[00m\r\n",
      "    â”œâ”€â”€ \u001b[01;34m5ccfa64b243643f48f7fb0f11be8720f\u001b[00m\r\n",
      "    â”‚Â Â  â”œâ”€â”€ \u001b[01;34martifacts\u001b[00m\r\n",
      "    â”‚Â Â  â”œâ”€â”€ meta.yaml\r\n",
      "    â”‚Â Â  â”œâ”€â”€ \u001b[01;34mmetrics\u001b[00m\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ rmse_train\r\n",
      "    â”‚Â Â  â”‚Â Â  â””â”€â”€ rmse_val\r\n",
      "    â”‚Â Â  â”œâ”€â”€ \u001b[01;34mparams\u001b[00m\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ eta\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ gamma\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ lambda\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ min_child_weight\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ n_estimators\r\n",
      "    â”‚Â Â  â”‚Â Â  â””â”€â”€ objective\r\n",
      "    â”‚Â Â  â””â”€â”€ \u001b[01;34mtags\u001b[00m\r\n",
      "    â”‚Â Â      â”œâ”€â”€ mlflow.source.git.commit\r\n",
      "    â”‚Â Â      â”œâ”€â”€ mlflow.source.name\r\n",
      "    â”‚Â Â      â”œâ”€â”€ mlflow.source.type\r\n",
      "    â”‚Â Â      â””â”€â”€ mlflow.user\r\n",
      "    â”œâ”€â”€ \u001b[01;34me622e8db0e3d4eb786959b83761d7e5c\u001b[00m\r\n",
      "    â”‚Â Â  â”œâ”€â”€ \u001b[01;34martifacts\u001b[00m\r\n",
      "    â”‚Â Â  â”œâ”€â”€ meta.yaml\r\n",
      "    â”‚Â Â  â”œâ”€â”€ \u001b[01;34mmetrics\u001b[00m\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ rmse_train\r\n",
      "    â”‚Â Â  â”‚Â Â  â””â”€â”€ rmse_val\r\n",
      "    â”‚Â Â  â”œâ”€â”€ \u001b[01;34mparams\u001b[00m\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ eta\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ gamma\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ lambda\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ min_child_weight\r\n",
      "    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ n_estimators\r\n",
      "    â”‚Â Â  â”‚Â Â  â””â”€â”€ objective\r\n",
      "    â”‚Â Â  â””â”€â”€ \u001b[01;34mtags\u001b[00m\r\n",
      "    â”‚Â Â      â”œâ”€â”€ mlflow.source.git.commit\r\n",
      "    â”‚Â Â      â”œâ”€â”€ mlflow.source.name\r\n",
      "    â”‚Â Â      â”œâ”€â”€ mlflow.source.type\r\n",
      "    â”‚Â Â      â””â”€â”€ mlflow.user\r\n",
      "    â””â”€â”€ meta.yaml\r\n",
      "\r\n",
      "27 directories, 55 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree mlruns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e015f",
   "metadata": {},
   "source": [
    "### Store logs in Sqlite Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf5d19",
   "metadata": {},
   "source": [
    "An alternative for storing all the logged outputs locally in a folder is to use a database to do so. Here we will use ```sqlite```. In order to tell mlflow to store things in a database we need to set the tracking urias ```mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")```. Alternatively we can export the environment variable ```export MLFLOW_TRACKING_URI sqlite:///mlflow.db```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64e2352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a29c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse training: 0.219\t rmse validation: 0.228\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=0):\n",
    "    train_rf(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb358ba4",
   "metadata": {},
   "source": [
    "This creates a database ```mlflow.db```, where the logged paramters and metrics are stored. We can check the entries using sqlite in the terminal:\n",
    "```\n",
    "sqlite3 mlflow.db\n",
    "sqlite3> .table --shows all tables in the database\n",
    "sqlite3> SELECT * FROM metrics --shows all metrics \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110980be",
   "metadata": {},
   "source": [
    "## Using the web ui for Visualization\n",
    "in the first case, when we store the logged parameters and metrics locally in ```.\\mlflow```, we can simply type ```mlflow ui``` in the terminal to the the results interactively. This is short for ```mlflow ui --backend-store-uri mlruns```\n",
    "\n",
    "In the second case, we need to change the ```backend-store-uri``` and use ```mlflow ui --backend-store-uri sqlite:///mlruns.db```. In order for this to work sqlalchemy needs to be installed.\n",
    "\n",
    "Another useful paramter is ```--port``` to change the port for the ui. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1acec195",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16b555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
